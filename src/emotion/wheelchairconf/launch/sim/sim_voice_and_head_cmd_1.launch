<!-- Run a simulation using the voice_and_head controller, to move say "ok wheelchair go", "ok wheelchair back", "ok wheelchair left"-->
<!-- Make sure that the microphone is connected and working :) -->
<!-- Make sure that you have internet to use google recognizer:) -->
<!-- Connect the kinect -->

<launch>
	<arg name="camera" default="camera" />
	#Start the kinect
	<include file="$(find openni_launch)/launch/openni.launch">
		<!-- "camera" should uniquely identify the device. All topics are pushed down
       into the "camera" namespace, and it is prepended to tf frame ids. -->
		<arg name="camera" value="$(arg camera)"/>
		<!-- device_id can have the following formats:
         "B00367707227042B": Use device with given serial number
         "#1"              : Use first device found
         "2@3"             : Use device on USB bus 2, address 3
	 	"2@0"             : Use first device found on USB bus 2
    	-->
  		<!--arg name="device_id" default="#1" /-->
	</include>

	##### START RVIZ   #####
	<node pkg="rviz" type="rviz" name="rviz" args="-d $(find wheelchairconf)/config/rviz/sim_voice_and_head_cmd.rviz"/>


</launch>
