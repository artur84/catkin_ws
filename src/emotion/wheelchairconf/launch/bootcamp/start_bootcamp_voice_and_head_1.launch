<!-- Run a simulation using the voice_and_head controller, to move say "ok wheelchair go", "ok wheelchair back", "ok wheelchair left"-->
<!-- Make sure that the microphone is connected and working :) -->
<!-- Make sure that you have internet to use google recognizer:) -->
<!-- Connect the kinect -->


<!-- I got many troubles when trying to launch openni.launch and kinect_face_pose_estimator.launch file together
	so normally you should first start openni.launch and then use this file -->



<launch>
	<arg name="sim" default="1"/>
	<arg name="camera" default="camera" />
	#Start the kinect
	<include file="$(find openni_launch)/launch/openni.launch">
		<!-- "camera" should uniquely identify the device. All topics are pushed down
       into the "camera" namespace, and it is prepended to tf frame ids. -->
		<arg name="camera" value="$(arg camera)"/>
		<!-- device_id can have the following formats:
         "B00367707227042B": Use device with given serial number
         "#1"              : Use first device found
         "2@3"             : Use device on USB bus 2, address 3
	 	"2@0"             : Use first device found on USB bus 2
    	-->
  		<!--arg name="device_id" default="#1" /-->
	</include>

	##### START RVIZ   #####
	<group if="$(arg sim)">
		<node pkg="rviz" type="rviz" name="rviz" args="-d $(find wheelchairconf)/config/rviz/sim_bootcamp_voice_and_head.rviz"/>
	</group>

	<group unless="$(arg sim)">
		<node pkg="rviz" type="rviz" name="rviz" args="-d $(find wheelchairconf)/config/rviz/demo_bootcamp_voice_and_head.rviz"/>
	</group>


</launch>
